the lower number the higher priority
1 在服务器上把[官方文档](site)上的zero_out op编译和测试出来
	site=https://www.tensorflow.org/extend/adding_an_op
	我试过自己写的myctc op编译成功，但是测试会报错undefined symbol
	为了排除是自己代码问题还是编译方式问题，我编译了样例zero_out op，测试报了一样的错
	代码在/usr/whz/audio_attack/myctc，build.sh是编译的几条指令
	
	
2 去看[论文](ref)，先看懂梯度怎么求的，然后弄清楚myctc改了什么地方，实现新的梯度
	ref=Connectionist Temporal Classification: Labeling Unsegmented Sequence Data with Recurrent Neural Networks
	已经实现的代码在https://github.com/HazekiahWon/audio_attack.git的ctc.py，ctc_loss()是在别人的python实现上做的改动，已经包含原梯度实现
	访问repo前首先接受邀请https://github.com/HazekiahWon/audio_attack/invitations
	梯度实现建议先写python，再按照pythoncode，根据官方文档的规则写gradient的cppcode
	
3 去看(audio_attack),(cyclegan),(speech enhancement gan),后两者主要是代码,先做各自的运行，再一点点整合
	希望把cyclegan的两个G换成segan的主体，因为segan是waveform到waveform
	audio_attack的方法及myctc的改进作为生成训练数据的方法。
	现在是作为unsupervised用unpaired data，如果发现不work会改成supervised，那么就把pix2pix替换cyclegan
	
4 针对audio_attack中选择的target_model=DeepSpeech，写代码实现：给定一个clean example，去画decision boundary
	这个想法不完整。想要参考一下对rnn的interpretability或者geometry的论文是怎么做的
	和cnn不一样，rnn是时间序列，在每个时间点都做分类，那么要怎么研究geometry
=====================================================================================
1	官方说明https://www.tensorflow.org/extend/adding_an_op
	另一个教程https://davidstutz.de/implementing-tensorflow-operations-in-c-including-gradients/
	都试过样例，都没有成功，第一个报错和第二个还不一样，第二个是cmake编译
===== 0810 =====
1   重装了tensorflow后可以正常编译运行了，但是我写的代码运行不了
    顺藤摸瓜找到了
    =1= https://github.com/tensorflow/tensorflow/blob/814f9ccd9b34a828f93d33eee6265e0cac07095a/tensorflow/core/kernels/ctc_loss_op.cc
    这是编译ctc_loss的cc
    =2= 相关的源码
    https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/core/util/ctc/ctc_loss_calculator.cc
    和ctc_loss_calculator.h
    所以我打算就着源码去改
===== 0811 =====
0 修改意见
===== A ======
	1. define context C in detail (line125 to first para. of sec.3 )
	2. definition for functions such as mask, fusion, temporal_fusion 
	>> this is to know how the attention is computed
	at least high level intuitions are required
	3. lack of dimensionality specific in the model (suggesting the graph is needed)
	4. typo : line 122 and line 120 C'; line 206; line 236; line 256 dtm_datn
	5. abbrv. specified at first use
	6. test set, we should notify that this is the standard testing test used in all relevant work
	>> the review suggest that we provide results in larger dataset
	7. descriptions and reference for prev. state-of-art models
	8. sampling scheme's descriptions are missing
===== B =====
	1. more justification for proposed network design
	>> c.f. simple feedforward (because ours is recurrent)
	2. more explanations on attention module and justification (quantitative), like:
	replace attention module with standard denseblock
	3. table3 references to prior work
	4. context frames
===== C =====
	1. attention module's effect on mis-aligned contexts due to large motions
	>> motion compensation deals with large motion
	2. show changes of acc by changing #context frames
==> prove convergence?
organization of current paper:

===== 3 =====
	1. the task, with annotations (generated y, x, c, h, w, r)
	== 3.1 ==
	1. three-agent high-level respective functions
	2. minimax(typo??) game formulation
	3. underscore the function of Datn, point out the core problem, introduce a bit intuition
	== 3.1.1 Generator ==
	1. formulate as seq2seq with encoder-decoder structure. G's input and output
	2. the pipeline : encoder, attention, decoder functions
	>> here we have mentioned the computational graph
	**A3** dimensionality
	3. encoder : formular, interior stucture (components), usage (for current and contexts)
	4. attention : motivation (temporal corr.)
	>> visual attention mask : functions and intuitions, formulas
	**A2** formulas for mask,fusion
	**A8** here we mentioned in the last paragragh, we use periodical sampling
	5. decoder : representation learning + neighboring fusion + upscling
	**A2** formula for temporal_fusion
	>> sell ideas about temporal fusion
	== 3.1.2 Temporal Dis ==
	12. mention the temporal profile preprocessing
	last. justify that do not accept cinput
	== 3.1.3 Atn Dis ==
	1. functions, input, output,
	2. typo of reference 3.1.3(should be 3.3), talking about where comes the samples
	== 3.2 loss ==
	Dt : jsd loss
	Datn : intuitions of the interactions between Dt and Datn
	G : two loss term
	== 3.3 traning scheme ==
	brief restatement of the alg
	**A8**
===== 4 experiments ======
	1. dataset
	2. traning related
	3. arbitrary structure mentioning, introduce our specific design
	4. ?? **A5** all abbrv. specified at first
	== 4.1 ablation ==
	1. benchmark dataset??
	**A6** we need to show that the test set is used in all prior work and thus an acknowledged one.
	2. neighboring fusion
	3. attention
	4. adv.
	5. Dt
	== 4.2 comparison ==
	1. some conventions
	**A7** references for prior work are forgotten
	**A4** in the text, we forget to modify that dtm_datn to datn_dt
	== 5 conclusion ==
	
	
===== 0813 ======
已经改了一些typo
修改意见
3
可能还要写清楚context是在同一个video里面非input x之外的frame
3.1.1 
有关G的dimensionality应该有张图
attention那里，其实已经指出了和residual attention network类似的结构，但可能还需要把mask,fusion式子写出来
关于attention的context是如何periodical sampling的可能要补充一下
decoder那里，temporal_fusion的式子，其实这些fusion就是concat+1x1conv
3.1.3
提到样本从哪里来这个问题会进一步讨论，我粗看这个引用好像就是在3.3的alg.，不知道有没有问题
4
关于后文的缩写，不知道是不是要在这里先交代了
4.1
在dataset那里可能还要强调一下test set之所以只有四个是因为之前大家都用的是这四个，而且比较难
4.2 
不知道是不是在比较的同时还要提一下其他的模型
==》 关于证明收敛，在考虑能不能用EM算法，以及之前何旭明说从game theory的角度
==》 关于context 个数的实验